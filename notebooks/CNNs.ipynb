{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "The following notebook presents the CNN approach to sentence boundary detection. Similarily to previous attempts is also has the problem of not allowing variable length. Thus, what we concentrate here on is a given amount of time before and afterwards of the break. This might (in case of a pause) or might not imply discontinuities. In general all features are initially calculated on the original, long data and then split into smaller word elements depending on the frame size. This is very important as if we calculate the features on the cut data we will influence the edges and hence change how the situation looks like.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wants not to use all possible GPUs, the following will set the devices to be used. Here, we use device with id 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import os\n",
    "from sklearn.utils import class_weight\n",
    "from keras.layers import Dense, Dropout, Concatenate, Input, MaxPool1D, MaxPool2D, AveragePooling1D, AveragePooling2D, Flatten, Conv2D, Conv1D, BatchNormalization, ReLU\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import create_data_frame\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the training files and validation files lists by globbing the initially prepared directories. The data format expected is rttm which exists in the broadcast and switchboard datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = glob.glob(\"data/broadcast/train/*.rttm\")\n",
    "validation_files = glob.glob(\"data/broadcast/validation/*.rttm\")\n",
    "#training_files, validation_files = train_test_split(files, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prepare data routine allows us to, by providing the basic information about the file, obtain all the necessary features. It operates on frames rather than time, hence, the factor $\\dfrac{sr}{512}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, audio, sr, size):\n",
    "    # Obtain the chroma (pitch), mfcc and energy features\n",
    "    print(\"Obtaining chroma\")\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "    print(\"Obtaining chroma [DONE]\")\n",
    "    print(\"Obtaining mfcc\")\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=50)\n",
    "    print(\"Obtaining mfcc [DONE]\")\n",
    "    print(\"Obtaining energy\")\n",
    "    energy = librosa.feature.rms(y=audio)\n",
    "    print(\"Obtaining energy [DONE]\")\n",
    "    \n",
    "    mfcc_features = []\n",
    "    chroma_features = []\n",
    "    energy_features = []\n",
    "    pause = []\n",
    "    turn = []\n",
    "    y = []\n",
    "    \n",
    "    # Crawl through the rows of the data frame and add the features     \n",
    "    for index, row in df.iterrows():\n",
    "        start = int(round(row['beginning_time']*sr/512))\n",
    "        finish = int(round(row['final_time']*sr/512))\n",
    "                \n",
    "        try:\n",
    "            start_next = int(round(df.loc[index+1, 'beginning_time']*sr/512))\n",
    "            moved_finish = finish - size\n",
    "            moved_next_start = start_next + size\n",
    "            \n",
    "            mfcc_features.append(np.concatenate((mfcc[:, moved_finish:finish], mfcc[:, start_next:moved_next_start]), axis=1))\n",
    "            chroma_features.append(np.concatenate((chroma[:, moved_finish:finish], chroma[:, start_next:moved_next_start]), axis=1))\n",
    "            energy_features.append(np.concatenate((energy[:, moved_finish:finish], energy[:, start_next:moved_next_start]), axis=1))\n",
    "            \n",
    "        except KeyError:\n",
    "            moved_finish = finish - size\n",
    "            if energy.shape[1] > finish + size:\n",
    "                mfcc_features.append(mfcc[:, moved_finish:finish + size])\n",
    "                chroma_features.append(chroma[:, moved_finish:finish + size])\n",
    "                energy_features.append(energy[:, moved_finish:finish + size])\n",
    "            else:\n",
    "                mfcc_features.append(np.concatenate((mfcc[:, moved_finish:finish], np.zeros([mfcc.shape[0], size])), axis=1))\n",
    "                chroma_features.append(np.concatenate((chroma[:, moved_finish:finish], np.zeros([chroma.shape[0], size])), axis=1))\n",
    "                energy_features.append(np.concatenate((energy[:, moved_finish:finish], np.zeros([energy.shape[0], size])), axis=1))\n",
    "                \n",
    "        pause.append(row['pause'])\n",
    "        turn.append(row['turn'])\n",
    "        y.append(row['end_of_sentence'])\n",
    "\n",
    "    return mfcc_features, chroma_features, energy_features, pause, turn, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the data we need to normalise it. This step is quite popular in machine learning as it allows to drastically decrease the training time and improves the convergance of the function. Here a typical normalisation is used, i.e. $\\dfrac{x-\\mu}{\\sigma}$, where $\\mu$ is the mean and $\\sigma$ is the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(files, mfcc_norm=None, energy_norm=None, pause_norm=None):\n",
    "    features = [[], [], [], [], []]\n",
    "    y = []\n",
    "    \n",
    "    for index, file in enumerate(files):\n",
    "        print(f\"Starting analysing file number {index + 1} out of {len(files)}\")\n",
    "        df = create_data_frame((file,))\n",
    "        base = os.path.splitext(file)[0] + '.wav'\n",
    "        \n",
    "        print(\"Reading audio\")\n",
    "        audio, sr = librosa.load(base, sr=None)\n",
    "        print(\"Reading audio [DONE]\")\n",
    "        current = prepare_data(df, audio, sr, 10)\n",
    "        features[0] += current[0]\n",
    "        features[1] += current[1]\n",
    "        features[2] += current[2]\n",
    "        features[3] += current[3]\n",
    "        features[4] += current[4]\n",
    "        \n",
    "        y += current[5]\n",
    "        \n",
    "    print(\"Normalising data\")\n",
    "    if not mfcc_norm:\n",
    "        mfcc_norm = (np.mean(features[0]), np.std(features[0]))\n",
    "\n",
    "    if not energy_norm:\n",
    "        energy_norm = (np.mean(features[2]), np.std(features[2]))\n",
    "\n",
    "    if not pause_norm:\n",
    "        pause_norm = (np.mean(features[3]), np.std(features[3]))\n",
    "\n",
    "    features[0] = (np.stack(features[0]) - mfcc_norm[0])/mfcc_norm[1]\n",
    "    features[0] = np.reshape(features[0], (features[0].shape[0], features[0].shape[1], features[0].shape[2], 1))\n",
    "    \n",
    "    features[1] = np.stack(features[1])\n",
    "    features[1] = np.reshape(features[1], (features[1].shape[0], features[1].shape[1], features[1].shape[2], 1))\n",
    "\n",
    "    features[2] = np.transpose((np.stack(features[2]) - energy_norm[0])/energy_norm[1], (0, 2, 1))\n",
    "    features[3] = (np.stack(features[3]) - pause_norm[0])/pause_norm[1]\n",
    "    features[4] = np.stack(features[4])\n",
    "    print(\"Normalising data [DONE]\")\n",
    "    \n",
    "    return features, np.stack(y), mfcc_norm, energy_norm, pause_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we obtain the features and also obtain the normalising factors to be used for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysing file number 1 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 2 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 3 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 4 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 5 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 6 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 7 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 8 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 9 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 10 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 11 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 12 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 13 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 14 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 15 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 16 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 17 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 18 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 19 out of 19\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Normalising data\n",
      "Normalising data [DONE]\n",
      "Starting analysing file number 1 out of 2\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Starting analysing file number 2 out of 2\n",
      "Reading audio\n",
      "Reading audio [DONE]\n",
      "Obtaining chroma\n",
      "Obtaining chroma [DONE]\n",
      "Obtaining mfcc\n",
      "Obtaining mfcc [DONE]\n",
      "Obtaining energy\n",
      "Obtaining energy [DONE]\n",
      "Normalising data\n",
      "Normalising data [DONE]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, mfcc_norm, energy_norm, pause_norm = preprocess(training_files)\n",
    "x_test, y_test, _, _, _ = preprocess(validation_files, mfcc_norm, energy_norm, pause_norm) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check we confirm that the shape of the training data is consitent. This test is quite manual as it requires to set the shape to be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether all dimensions are the same\n",
    "for index, i in enumerate(x_train[0]):\n",
    "    if i.shape != (50, 20, 1):\n",
    "        print(\"ups\")\n",
    "        print(i.shape)\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the recall, presicion, f1 and nist scores that are unavailable in keras/tensorflow by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define help functions for f-score, etc.\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def nist(y_true, y_pred):\n",
    "    predicted = K.round(K.clip(y_pred, 0, 1))\n",
    "    return K.sum(K.abs(predicted-y_true))/K.sum(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural model used in this notebook is a CNN network. It consists of multiple layers and uses some of the common techniques to counteract problems such as overfitting and data imbalance.\n",
    "We start with five inputs. Each of them is treated a bit differently. All the time dependent qunatities (such as MFCC, chroma and energy) are fed through separate CNN's with variable 2D conv layers. All the layers are normalised using batch normalisation and ReLu is the activation function used. Batch normalisation is a very good measure against overfitting and comes from the idea that if it is good to normalise the input data, why not normalise the intermediate stages as well. In the end we flatten the layers and concatenate them with the pause duration and information about the turn of the speaker. Afterwards, this is fed through a fully connected layers that can be used toghether with a dropout layer. The dropout layer here counteracts overfitting and in essence gives the network the opprotunity to test multiple models in one. The adam optimizer is used as it is almost always the standard. Other optimizers seem not to converge as nicely as adam does and take more time to conduct. The loss function used is the binary crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(conv_size, number_of_deep_layers, size_of_deep_layers, dropout_size):\n",
    "    # Define inputs\n",
    "    mfcc_input = Input(shape=(50, 20, 1))\n",
    "    chroma_input = Input(shape=(12, 20, 1))\n",
    "    energy_input = Input(shape=(20, 1))\n",
    "    pause_input = Input(shape=(1,))\n",
    "    turn_input = Input(shape=(1,))\n",
    "    \n",
    "    # MFCC CNN\n",
    "    mfcc = Conv2D(16, (3, 3), padding='same')(mfcc_input)\n",
    "    mfcc = BatchNormalization()(mfcc)\n",
    "    mfcc = ReLU()(mfcc)\n",
    "    mfcc = MaxPool2D()(mfcc)\n",
    "    for _ in range(conv_size):\n",
    "        mfcc = Conv2D(32, (3, 3), padding='same')(mfcc)\n",
    "        mfcc = BatchNormalization()(mfcc)\n",
    "        mfcc = ReLU()(mfcc)\n",
    "    mfcc = AveragePooling2D()(mfcc)\n",
    "    mfcc = Flatten()(mfcc)\n",
    "    \n",
    "    # Chroma CNN\n",
    "    chroma = Conv2D(16, (3, 3), padding='same')(chroma_input)\n",
    "    chroma = BatchNormalization()(chroma)\n",
    "    chroma = ReLU()(chroma)\n",
    "    chroma = MaxPool2D()(chroma)\n",
    "    for _ in range(conv_size):\n",
    "        chroma = Conv2D(32, (3, 3), padding='same')(chroma)\n",
    "        chroma = BatchNormalization()(chroma)\n",
    "        chroma = ReLU()(chroma)\n",
    "    chroma = AveragePooling2D()(chroma)\n",
    "    chroma = Flatten()(chroma)\n",
    "    \n",
    "    # Energy CNN\n",
    "    energy = Conv1D(16, 3, padding='same')(energy_input)\n",
    "    energy = BatchNormalization()(energy)\n",
    "    energy = ReLU()(energy)\n",
    "    energy = MaxPool1D()(energy)\n",
    "    for _ in range(conv_size):\n",
    "        energy = Conv1D(32, 3, padding='same')(energy)\n",
    "        energy = BatchNormalization()(energy)\n",
    "        energy = ReLU()(energy)\n",
    "    energy = AveragePooling1D()(energy)\n",
    "    energy = Flatten()(energy)\n",
    "    \n",
    "    # Concatenate layers\n",
    "    x = Concatenate()([mfcc, chroma, energy, pause_input, turn_input])\n",
    "    #x = Dropout(dropout_size)(x)\n",
    "    # Post dense layers\n",
    "    for i in range(number_of_deep_layers):\n",
    "        x = Dense(size_of_deep_layers, activation='relu')(x)\n",
    "        #x = Dropout(dropout_size)(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Compile the model\n",
    "    model = Model(inputs=[mfcc_input, chroma_input, energy_input, pause_input, turn_input], outputs=x)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', f1_m, precision_m, recall_m, nist])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example we can summarise a given network and see how many parameters we will obtain. Depending on the setup this can vary significantly, from couple thousand to millions of parameters. Those control how complex the function we are estimating can be and how easily it can overfit. Hence, too small number and we will underfit, too big and we will overfit. To help visualise the network we also plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1006 19:35:01.345139 140189795104576 deprecation_wrapper.py:119] From /local/scratch/mac224/anaconda/envs/SUNDER/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1006 19:35:01.416724 140189795104576 deprecation_wrapper.py:119] From /local/scratch/mac224/anaconda/envs/SUNDER/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1006 19:35:01.443614 140189795104576 deprecation_wrapper.py:119] From /local/scratch/mac224/anaconda/envs/SUNDER/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1006 19:35:01.489161 140189795104576 deprecation_wrapper.py:119] From /local/scratch/mac224/anaconda/envs/SUNDER/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1006 19:35:01.491171 140189795104576 deprecation_wrapper.py:119] From /local/scratch/mac224/anaconda/envs/SUNDER/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1006 19:35:10.650588 140189795104576 deprecation_wrapper.py:119] From /local/scratch/mac224/anaconda/envs/SUNDER/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1006 19:35:10.756576 140189795104576 deprecation_wrapper.py:119] From /local/scratch/mac224/anaconda/envs/SUNDER/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1006 19:35:10.758999 140189795104576 deprecation_wrapper.py:119] From /local/scratch/mac224/anaconda/envs/SUNDER/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1_m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-44a233b81b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Summarize and plot example model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m652\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-96ac2fa08efb>\u001b[0m in \u001b[0;36mCNN_model\u001b[0;34m(conv_size, number_of_deep_layers, size_of_deep_layers, dropout_size)\u001b[0m\n\u001b[1;32m     57\u001b[0m     model.compile(optimizer='adam',\n\u001b[1;32m     58\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                   metrics=['accuracy', f1_m, precision_m, recall_m, nist])\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_m' is not defined"
     ]
    }
   ],
   "source": [
    "# Summarize and plot example model\n",
    "model = CNN_model(0, 1, 652, 0.1)\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tune the hyperparameters we define some lists to test over. Those allow us to run long experiments and see in which direction we should perturb the network in order for it to work the best. Validation set can have a big influence on the obtained result, hence, we use a constant one obtained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layers to test\n",
    "conv_sizes = [2,]#np.arange(0, 10)\n",
    "numbers_hidden = [1,]#np.arange(1, 5)\n",
    "sizes_hidden = [652,]#np.arange(20, 160, 40)\n",
    "dropout_sizes = [0,]#np.arange(0.2, 0.7, 0.1)\n",
    "\n",
    "# Define the wieghts to use\n",
    "weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weigths = {index: value for index, value in enumerate(weights)}\n",
    "\n",
    "# Go through the posssible sizes and evaluate the model\n",
    "for dropout in dropout_sizes:\n",
    "    for conv in conv_sizes:\n",
    "        for size in sizes_hidden:\n",
    "            for number in numbers_hidden:\n",
    "                model = CNN_model(conv, number, size, dropout)\n",
    "\n",
    "                name = f'Broadcast-new-validation-no-dropout-CNN-mfcc-chroma-energy-pause-turn-automatic-input-weights-number-conv-{conv}-dropout-{dropout}-number-hidden-{number}-size-hidden-{size}-{datetime.now().strftime(\"%d_%m_%Y-%H_%M_%S\")}'\n",
    "                checkpoint = ModelCheckpoint(f'training/{name}.h5', monitor='val_f1_m', verbose=1, save_best_only=True, mode='max')\n",
    "                tensorboard = TensorBoard(log_dir=f\"training/tensorboard/{name}\")\n",
    "                #early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=6, min_delta=0.001)\n",
    "\n",
    "                model.fit(x_train, y_train, epochs=1000, batch_size=1000, callbacks=[checkpoint, tensorboard], validation_data=(x_test, y_test), shuffle=True, class_weight=weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
